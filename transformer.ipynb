{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n",
      "Epoch 1/30\n",
      "Epoch [1/30], Loss: 1.5700\n",
      "Epoch 2/30\n",
      "Epoch [2/30], Loss: 1.5398\n",
      "Epoch 3/30\n",
      "Epoch [3/30], Loss: 1.5799\n",
      "Epoch 4/30\n",
      "Epoch [4/30], Loss: 1.5377\n",
      "Epoch 5/30\n",
      "Epoch [5/30], Loss: 1.5532\n",
      "Epoch 6/30\n",
      "Epoch [6/30], Loss: 1.5833\n",
      "Epoch 7/30\n",
      "Epoch [7/30], Loss: 1.5703\n",
      "Epoch 8/30\n",
      "Epoch [8/30], Loss: 1.5792\n",
      "Epoch 9/30\n",
      "Epoch [9/30], Loss: 1.5813\n",
      "Epoch 10/30\n",
      "Epoch [10/30], Loss: 1.6030\n",
      "Epoch 11/30\n",
      "Epoch [11/30], Loss: 1.5596\n",
      "Epoch 12/30\n",
      "Epoch [12/30], Loss: 1.5980\n",
      "Epoch 13/30\n",
      "Epoch [13/30], Loss: 1.6628\n",
      "Epoch 14/30\n",
      "Epoch [14/30], Loss: 1.5629\n",
      "Epoch 15/30\n",
      "Epoch [15/30], Loss: 1.5529\n",
      "Epoch 16/30\n",
      "Epoch [16/30], Loss: 1.5567\n",
      "Epoch 17/30\n",
      "Epoch [17/30], Loss: 1.6090\n",
      "Epoch 18/30\n",
      "Epoch [18/30], Loss: 1.5629\n",
      "Epoch 19/30\n",
      "Epoch [19/30], Loss: 1.5577\n",
      "Epoch 20/30\n",
      "Epoch [20/30], Loss: 1.5564\n",
      "Epoch 21/30\n",
      "Epoch [21/30], Loss: 1.5484\n",
      "Epoch 22/30\n",
      "Epoch [22/30], Loss: 1.5952\n",
      "Epoch 23/30\n",
      "Epoch [23/30], Loss: 1.5380\n",
      "Epoch 24/30\n",
      "Epoch [24/30], Loss: 1.6017\n",
      "Epoch 25/30\n",
      "Epoch [25/30], Loss: 1.5587\n",
      "Epoch 26/30\n",
      "Epoch [26/30], Loss: 1.5801\n",
      "Epoch 27/30\n",
      "Epoch [27/30], Loss: 1.5556\n",
      "Epoch 28/30\n",
      "Epoch [28/30], Loss: 1.5914\n",
      "Epoch 29/30\n",
      "Epoch [29/30], Loss: 1.6033\n",
      "Epoch 30/30\n",
      "Epoch [30/30], Loss: 1.5416\n",
      "Dev Loss: 1.5635\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataloader import get_dataloaders, MAX_SEQ_LENGTH, vocab_size\n",
    "import time\n",
    "\n",
    "class RNAPairTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, nhead=8, device='cpu'):\n",
    "        super(RNAPairTransformer, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim # 输入维度，vocab_size\n",
    "        self.hidden_dim = hidden_dim # Transformer模型中每一层的特征向量维度\n",
    "        self.output_dim = output_dim  # 输出维度，vocab_size\n",
    "        self.num_layers = num_layers # Transformer模型中encoder和decoder的层数\n",
    "        self.device = device\n",
    "\n",
    "        # Embedding layer for one-hot encoded input\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim) # 每个碱基都有一个固定的特征向量表示\n",
    "        self.positional_encoding = self._generate_positional_encoding(MAX_SEQ_LENGTH, hidden_dim) # 位置编码\n",
    "\n",
    "        # Transformer Encoder-Decoder\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=nhead, # 多头注意力机制的头数\n",
    "            num_encoder_layers=num_layers, # encoder层数\n",
    "            num_decoder_layers=num_layers, # decoder层数\n",
    "            dim_feedforward=hidden_dim * 4, # 前馈网络中隐层的维度\n",
    "            batch_first=True, # 输入数据的形状为(batch_size, seq_length, feature_dim)。\n",
    "            # dropout=0.1, # dropout概率\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # 利用一个全连接层将隐藏层的特征向量映射到输出维度\n",
    "\n",
    "    def _generate_positional_encoding(self, seq_length, hidden_dim):\n",
    "        position = torch.arange(0, seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_dim, 2).float() * -(torch.log(torch.tensor(10000.0)) / hidden_dim)\n",
    "        )\n",
    "        positional_encoding = torch.zeros(seq_length, hidden_dim)\n",
    "        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "        return positional_encoding\n",
    "    \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Generate target mask\n",
    "        self.tgt_mask = self._generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        # Add positional encoding to embeddings\n",
    "        src_emb = self.embedding(src) + self.positional_encoding[:, : src.size(1), :].to(self.device)\n",
    "        tgt_emb = self.embedding(tgt) + self.positional_encoding[:, : tgt.size(1), :].to(self.device)\n",
    "        # Pass through Transformer\n",
    "        transformer_output = self.transformer(src_emb, tgt_emb, tgt_mask=self.tgt_mask)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.fc(transformer_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cpu'):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for seq1, seq2 in train_loader:\n",
    "            seq1, seq2 = seq1.to(device), seq2.to(device)\n",
    "\n",
    "            # Shift target sequence for decoder input\n",
    "            tgt_input = seq2[:, :-1]\n",
    "            tgt_output = seq2[:, 1:]\n",
    "\n",
    "            outputs = model(seq1, tgt_input)\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), tgt_output.reshape(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, dev_loader, criterion, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for seq1, seq2 in dev_loader:\n",
    "            seq1, seq2 = seq1.to(device), seq2.to(device)\n",
    "\n",
    "            # Shift target sequence for decoder input\n",
    "            tgt_input = seq2[:, :-1]\n",
    "            tgt_output = seq2[:, 1:]\n",
    "\n",
    "            outputs = model(seq1, tgt_input)\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), tgt_output.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Dev Loss: {total_loss / len(dev_loader):.4f}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    input_dim = vocab_size\n",
    "    hidden_dim = 128\n",
    "    output_dim = vocab_size\n",
    "    num_layers = 4\n",
    "    nhead = 8\n",
    "    num_epochs = 30\n",
    "    learning_rate = 1e-2\n",
    "    batch_size = 32\n",
    "\n",
    "    # Device configuration\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print('Using ' + device)\n",
    "\n",
    "    # Load data\n",
    "    train_loader, dev_loader, test_loader = get_dataloaders(batch_size=batch_size, one_hot_encode=False, start_token=True)\n",
    "\n",
    "    # Initialize model, criterion and optimizer\n",
    "    model = RNAPairTransformer(input_dim, hidden_dim, output_dim, num_layers, nhead, device).to(device)\n",
    "    weight = torch.tensor([1, 1, 1, 1, 1, 0.01, 1, 1], dtype=torch.float32, requires_grad=False).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.99 ** epoch)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'transformer_model.pth')\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, dev_loader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_dataloaders, MAX_SEQ_LENGTH, vocab_size, vocabulary\n",
    "import torch.nn as nn\n",
    "import random\n",
    "batch_size = 1\n",
    "train_loader, dev_loader, test_loader = get_dataloaders(batch_size=batch_size, one_hot_encode=False, start_token=True)\n",
    "# random select 5 training samples\n",
    "random.seed(0)\n",
    "train_samples = random.sample(list(train_loader), 10)\n",
    "# random select 5 dev samples\n",
    "dev_samples = random.sample(list(dev_loader), 10)\n",
    "# random select 5 test samples\n",
    "test_samples = random.sample(list(test_loader), 5)\n",
    "\n",
    "vocab = list(vocabulary.keys())\n",
    "def outputs_to_seq(outputs, flag=False):\n",
    "    if flag:\n",
    "        print(outputs)\n",
    "        outputs = outputs.argmax(dim=-1)\n",
    "    # print(outputs.shape)\n",
    "    outputs = [vocab[i] for i in outputs]\n",
    "    if 'P' in outputs:\n",
    "        outputs = outputs[:outputs.index('P')]\n",
    "    if 'E' in outputs:\n",
    "        outputs = outputs[:outputs.index('E')]\n",
    "    return outputs\n",
    "\n",
    "model.eval()\n",
    "# 输出原来的seq1和seq2，还有预测的seq2\n",
    "for i in range(10):\n",
    "    seq1, seq2 = train_samples[i]\n",
    "    seq1 = seq1.to(device)\n",
    "    seq2 = seq2.to(device)\n",
    "    tgt_input = seq2[:, :-1]\n",
    "    tgt_output = seq2[:, 1:]\n",
    "    outputs = model(seq1, tgt_input)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(outputs.reshape(-1, outputs.size(-1)), tgt_output.reshape(-1))\n",
    "    print(\"train loss: \", loss.item())\n",
    "    print(\"seq1: \", outputs_to_seq(seq1[0][1:]))\n",
    "    print(\"seq2: \", outputs_to_seq(seq2[0][1:]))\n",
    "    print(\"pred: \", outputs_to_seq(outputs[0], True))\n",
    "\n",
    "print(\"dev samples\")\n",
    "for i in range(10):\n",
    "    seq1, seq2 = dev_samples[i]\n",
    "    seq1 = seq1.to(device)\n",
    "    seq2 = seq2.to(device)\n",
    "    tgt_input = seq2[:, :-1]\n",
    "    tgt_output = seq2[:, 1:]\n",
    "    outputs = model(seq1, tgt_input)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(outputs.reshape(-1, outputs.size(-1)), tgt_output.reshape(-1))\n",
    "    print(\"train loss: \", loss.item())\n",
    "    print(\"seq1: \", outputs_to_seq(seq1[0][1:]))\n",
    "    print(\"seq2: \", outputs_to_seq(seq2[0][1:]))\n",
    "    print(\"pred: \", outputs_to_seq(outputs[0], True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
